{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/wandb/edu/blob/main/llm-apps-course/notebooks/01.%20Using_APIs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<!--- @wandbcode{llmapps-intro} -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding LLM APIs\n",
    "\n",
    "We will explore OpenAI models API to generate text.\n",
    "\n",
    "<!--- @wandbcode{llmapps-intro} -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "weave: Logged in as Weights & Biases user: nick99.\n",
      "weave: View Weave data at https://wandb.ai/itprodirect/llmapps/weave\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import tiktoken\n",
    "import wandb\n",
    "import weave\n",
    "from pprint import pprint\n",
    "from getpass import getpass\n",
    "from wandb.integration.openai import autolog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need an OpenAI API key to run this notebook. You can get one [here](https://platform.openai.com/account/api-keys)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key configured\n"
     ]
    }
   ],
   "source": [
    "if os.getenv(\"OPENAI_API_KEY\") is None:\n",
    "  if any(['VSCODE' in x for x in os.environ.keys()]):\n",
    "    print('Please enter password in the VS Code prompt at the top of your VS Code window!')\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass(\"Paste your OpenAI key from: https://platform.openai.com/account/api-keys\\n\")\n",
    "  openai.api_key = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "\n",
    "assert os.getenv(\"OPENAI_API_KEY\", \"\").startswith(\"sk-\"), \"This doesn't look like a valid OpenAI API key\"\n",
    "print(\"OpenAI API key configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's enable W&B autologging to track our experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">colorful-night-2</strong> at: <a href='https://wandb.ai/itprodirect/llmapps/runs/mj0igzsn' target=\"_blank\">https://wandb.ai/itprodirect/llmapps/runs/mj0igzsn</a><br> View project at: <a href='https://wandb.ai/itprodirect/llmapps' target=\"_blank\">https://wandb.ai/itprodirect/llmapps</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20260107_173433-mj0igzsn\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\user\\code\\wandb-edu\\llm-apps-course\\notebooks\\wandb\\run-20260107_175829-6p0g693r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/itprodirect/llmapps/runs/6p0g693r' target=\"_blank\">astral-universe-3</a></strong> to <a href='https://wandb.ai/itprodirect/llmapps' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/itprodirect/llmapps' target=\"_blank\">https://wandb.ai/itprodirect/llmapps</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/itprodirect/llmapps/runs/6p0g693r' target=\"_blank\">https://wandb.ai/itprodirect/llmapps/runs/6p0g693r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Initializing weave.\n",
      "weave: Logged in as Weights & Biases user: nick99.\n",
      "weave: View Weave data at https://wandb.ai/itprodirect/llmapps/weave\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wandb\n",
    "import weave\n",
    "from openai import OpenAI\n",
    "\n",
    "# optional: keep a W&B Run like the course expects\n",
    "wandb.init(project=\"llmapps\", job_type=\"introduction\")\n",
    "\n",
    "# this is the key: Weave auto-traces OpenAI calls\n",
    "weave.init(\"llmapps\")\n",
    "\n",
    "client = OpenAI()  # uses OPENAI_API_KEY from env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "weave: üç© https://wandb.ai/itprodirect/llmapps/r/call/019b9aaf-65f3-7558-8867-349bfb0fd8e7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "model = os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\")\n",
    "\n",
    "resp = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Say hi\"}],\n",
    ")\n",
    "\n",
    "print(resp.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[68119, 827, 139041, 268, 382, 15339, 0]\n",
      "Weights & Biases is awesome!\n"
     ]
    }
   ],
   "source": [
    "model = os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\")\n",
    "\n",
    "try:\n",
    "  encoding = tiktoken.encoding_for_model(model)\n",
    "except KeyError:\n",
    "  # gpt-4o family typically uses o200k_base; fallback to cl100k_base.\n",
    "  try:\n",
    "    encoding = tiktoken.get_encoding(\"o200k_base\")\n",
    "  except Exception:\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "text = \"Weights & Biases is awesome!\"\n",
    "enc = encoding.encode(text)\n",
    "print(enc)\n",
    "print(encoding.decode(enc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can decode the tokens one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68119\tWeights\n",
      "827\t &\n",
      "139041\t Bias\n",
      "268\tes\n",
      "382\t is\n",
      "15339\t awesome\n",
      "0\t!\n"
     ]
    }
   ],
   "source": [
    "for token_id in enc:\n",
    "    print(f\"{token_id}\\t{encoding.decode([token_id])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note how the leading tokens contain spacing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sample some text from the model. For this, let's create a wrapper function around the temperature parameters.\n",
    "Higher temperature will result in more random samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_temperature(temp):\n",
    "  response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Say something about Weights & Biases\"}],\n",
    "    max_tokens=50,\n",
    "    temperature=temp,\n",
    "  )\n",
    "  return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "weave: üç© https://wandb.ai/itprodirect/llmapps/r/call/019b9aba-cf30-7969-a022-0808e582ed27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('TEMP: 0, GENERATION: Weights & Biases (often abbreviated as W&B) is a '\n",
      " 'popular tool used in machine learning and deep learning for experiment '\n",
      " 'tracking, model management, and collaboration. It provides a platform for '\n",
      " 'data scientists and machine learning engineers to log their experiments, '\n",
      " 'visualize metrics')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "weave: üç© https://wandb.ai/itprodirect/llmapps/r/call/019b9aba-d528-7a6a-82e5-7ec18c5fb1ae\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('TEMP: 0.5, GENERATION: Weights & Biases (often abbreviated as W&B) is a '\n",
      " 'popular platform used for tracking machine learning experiments, visualizing '\n",
      " 'results, and collaborating on projects. It provides tools that help data '\n",
      " 'scientists and machine learning engineers manage their workflows more '\n",
      " 'effectively. Here are')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "weave: üç© https://wandb.ai/itprodirect/llmapps/r/call/019b9aba-dc23-78e8-b84a-a45baa4bbb05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('TEMP: 1, GENERATION: Weights & Biases (often abbreviated as W&B) is a '\n",
      " 'popular platform for machine learning experiment tracking, model '\n",
      " 'optimization, and collaboration. It provides tools that allow researchers '\n",
      " 'and data scientists to streamline their workflow by logging and visualizing '\n",
      " 'training processes in real-time')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "weave: üç© https://wandb.ai/itprodirect/llmapps/r/call/019b9aba-e136-7dde-b01c-544a5204907e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('TEMP: 1.5, GENERATION: Weights & Biases (often abbreviated as W&B) is a '\n",
      " 'platform designed to enhance the workflow of machine learning and data '\n",
      " 'science projects. It provides tools for tracking experiments, visualizing '\n",
      " 'metrics, managing datasets, and collaborating effectively within teams. \\n'\n",
      " '\\n'\n",
      " 'Here are')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "weave: üç© https://wandb.ai/itprodirect/llmapps/r/call/019b9aba-e882-773f-83e1-235482c734fb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('TEMP: 2, GENERATION: Weights & Biases (often abbreviated as '\n",
      " 'W&utm-equiv=&rial necessities suitableStrategyDeploylogical-assets-of(tool '\n",
      " \"betgSwiperParticipants.Start('.');\\n\"\n",
      " 'complex182‡¨≥gardbc d√∫vidas.nn communications Chengmuseum styl :</dcTF '\n",
      " 'missionary–Ω–µ–Ω–∏–π –ø—Ä–æ–±–ª–µ–º—ãcarbon Ultrsilent or Ëè≤cityrex')\n"
     ]
    }
   ],
   "source": [
    "for temp in [0, 0.5, 1, 1.5, 2]:\n",
    "  pprint(f'TEMP: {temp}, GENERATION: {generate_with_temperature(temp)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the [`top_p` parameter](https://platform.openai.com/docs/api-reference/completions/create#completions/create-top_p) to control the diversity of the generated text. This parameter controls the cumulative probability of the next token. For example, if `top_p=0.9`, the model will pick the next token from the top 90% most likely tokens. The higher the `top_p` the more likely the model will pick a token that it hasn't seen before. You should only use one of `temperature` or `top_p` at a given time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_topp(topp):\n",
    "  response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Say something about Weights & Biases\"}],\n",
    "    max_tokens=50,\n",
    "    top_p=topp,\n",
    "  )\n",
    "  return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "weave: üç© https://wandb.ai/itprodirect/llmapps/r/call/019b9abb-71bd-7428-b188-72746f1b4fb3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('TOP_P: 0.01, GENERATION: Weights & Biases (often abbreviated as W&B) is a '\n",
      " 'popular tool used in machine learning and deep learning for experiment '\n",
      " 'tracking, model management, and collaboration. It provides a platform for '\n",
      " 'data scientists and machine learning engineers to log their experiments, '\n",
      " 'visualize metrics')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "weave: üç© https://wandb.ai/itprodirect/llmapps/r/call/019b9abb-7b31-78f7-9f7a-ebeb88fd01dc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('TOP_P: 0.1, GENERATION: Weights & Biases (often abbreviated as W&B) is a '\n",
      " 'popular tool used in machine learning and deep learning for experiment '\n",
      " 'tracking, model management, and collaboration. It provides a platform for '\n",
      " 'data scientists and machine learning engineers to log their experiments, '\n",
      " 'visualize metrics')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "weave: üç© https://wandb.ai/itprodirect/llmapps/r/call/019b9abb-7ef9-7bdf-b3f0-087a109e2fa5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('TOP_P: 0.5, GENERATION: Weights & Biases (often abbreviated as W&B) is a '\n",
      " 'popular tool used in machine learning and deep learning to help researchers '\n",
      " 'and developers track experiments, visualize metrics, and manage datasets. It '\n",
      " 'provides a suite of features that facilitate collaboration and '\n",
      " 'reproducibility in')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "weave: üç© https://wandb.ai/itprodirect/llmapps/r/call/019b9abb-8695-716f-bbb0-9a4774ae9f70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('TOP_P: 1, GENERATION: Weights & Biases (often abbreviated as W&B) is a '\n",
      " 'popular machine learning and deep learning experiment tracking tool designed '\n",
      " 'to help data scientists and researchers manage their workflows. It provides '\n",
      " 'a suite of tools to track, visualize, and optimize machine learning models,')\n"
     ]
    }
   ],
   "source": [
    "for topp in [0.01, 0.1, 0.5, 1]:\n",
    "  pprint(f'TOP_P: {topp}, GENERATION: {generate_with_topp(topp)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's switch to chat mode and see how the model responds to our messages. We have some control over the model's response by passing a `system-role`, here we can steer to model to adhere to a certain behaviour.\n",
    "\n",
    "> We are using `gpt-3.5-turbo`, this model is faster and cheaper than `davinci-003`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "weave: üç© https://wandb.ai/itprodirect/llmapps/r/call/019b9abc-3d1a-77c4-be62-4926f76dd6e0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-CvX08PtuIAAxP6T2BCRtkojCzllUX', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Weights & Biases (often abbreviated as W&B) is a popular tool used in machine learning and deep learning for experiment tracking, model management, and collaboration. It provides a platform for data scientists and machine learning engineers to log their experiments, visualize metrics, and share results with their teams.\\n\\nKey features of Weights & Biases include:\\n\\n1. **Experiment Tracking**: W&B allows users to log hyperparameters, metrics, and system information during training runs. This helps in comparing different experiments and understanding the impact of various configurations on model performance.\\n\\n2. **Visualization**: The platform provides powerful visualization tools to analyze training progress, compare different runs, and visualize model performance over time. Users can create custom plots and dashboards to better understand their models.\\n\\n3. **Collaboration**: W&B facilitates collaboration among team members by allowing them to share results, insights, and visualizations easily. This is particularly useful in team settings where multiple people are working on different aspects of a project.\\n\\n4. **Model Management**: Users can version their models and datasets, making it easier to track changes and revert to previous versions if needed. This is crucial for maintaining reproducibility in machine learning projects.\\n\\n5. **Integration**: W&B integrates seamlessly with popular machine learning frameworks such as TensorFlow, PyTorch, Keras, and others, making it easy to incorporate into existing workflows.\\n\\n6. **Reports**: Users can create interactive reports that summarize their experiments, findings, and visualizations, which can be shared with stakeholders or used for presentations.\\n\\nOverall, Weights & Biases is a valuable tool for enhancing productivity and collaboration in machine learning projects, helping teams to build better models more efficiently.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1767827588, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_c4585b5b9c', usage=CompletionUsage(completion_tokens=340, prompt_tokens=25, total_tokens=365, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Say something about Weights & Biases\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, the response is a JSON object with relevant information about the request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Weights & Biases (often abbreviated as W&B) is a popular tool used in '\n",
      " 'machine learning and deep learning for experiment tracking, model '\n",
      " 'management, and collaboration. It provides a platform for data scientists '\n",
      " 'and machine learning engineers to log their experiments, visualize metrics, '\n",
      " 'and share results with their teams.\\n'\n",
      " '\\n'\n",
      " 'Key features of Weights & Biases include:\\n'\n",
      " '\\n'\n",
      " '1. **Experiment Tracking**: W&B allows users to log hyperparameters, '\n",
      " 'metrics, and system information during training runs. This helps in '\n",
      " 'comparing different experiments and understanding the impact of various '\n",
      " 'configurations on model performance.\\n'\n",
      " '\\n'\n",
      " '2. **Visualization**: The platform provides powerful visualization tools to '\n",
      " 'analyze training progress, compare different runs, and visualize model '\n",
      " 'performance over time. Users can create custom plots and dashboards to '\n",
      " 'better understand their models.\\n'\n",
      " '\\n'\n",
      " '3. **Collaboration**: W&B facilitates collaboration among team members by '\n",
      " 'allowing them to share results, insights, and visualizations easily. This is '\n",
      " 'particularly useful in team settings where multiple people are working on '\n",
      " 'different aspects of a project.\\n'\n",
      " '\\n'\n",
      " '4. **Model Management**: Users can version their models and datasets, making '\n",
      " 'it easier to track changes and revert to previous versions if needed. This '\n",
      " 'is crucial for maintaining reproducibility in machine learning projects.\\n'\n",
      " '\\n'\n",
      " '5. **Integration**: W&B integrates seamlessly with popular machine learning '\n",
      " 'frameworks such as TensorFlow, PyTorch, Keras, and others, making it easy to '\n",
      " 'incorporate into existing workflows.\\n'\n",
      " '\\n'\n",
      " '6. **Reports**: Users can create interactive reports that summarize their '\n",
      " 'experiments, findings, and visualizations, which can be shared with '\n",
      " 'stakeholders or used for presentations.\\n'\n",
      " '\\n'\n",
      " 'Overall, Weights & Biases is a valuable tool for enhancing productivity and '\n",
      " 'collaboration in machine learning projects, helping teams to build better '\n",
      " 'models more efficiently.')\n"
     ]
    }
   ],
   "source": [
    "pprint(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">astral-universe-3</strong> at: <a href='https://wandb.ai/itprodirect/llmapps/runs/6p0g693r' target=\"_blank\">https://wandb.ai/itprodirect/llmapps/runs/6p0g693r</a><br> View project at: <a href='https://wandb.ai/itprodirect/llmapps' target=\"_blank\">https://wandb.ai/itprodirect/llmapps</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20260107_175829-6p0g693r\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
